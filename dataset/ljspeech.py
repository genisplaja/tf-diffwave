import os

import librosa
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds


class LJSpeech:
    """LJ Speech dataset loader.
    Use other opensource vocoder settings, 16bit, sr: 22050.
    """
    SR = 22050
    MAXVAL = 32767.

    def __init__(self, config, data_dir=None, download=False, from_tfds=True):
        """Initializer.
        Args:
            config: Config, dataset configuration.
            data_dir: str, dataset directory
                , defaults to '~/tensorflow_datasets'.
            download: bool, download dataset or not.
            from_tfds: bool, load from tfrecord generated by tfds or read raw audio.
        """
        self.config = config
        self.rawset, self.info = self.load_data(data_dir, download, from_tfds)
        # [fft // 2 + 1, mel]
        melfilter = librosa.filters.mel(
            config.sr, config.fft, config.mel, config.fmin, config.fmax).T
        self.melfilter = tf.convert_to_tensor(melfilter)

        self.normalized = None

    def load_data(self, data_dir=None, download=False, from_tfds=True):
        """Load dataset from tfrecord or raw audio files.
        Args:
            data_dir: str, dataset directory.
                For from_tfds, None is acceptable
                 and set to default value '~/tensorflow_datasets'.
                For from raw audio, None is not acceptable.
            download: bool, download dataset or not, for from_tfds.
            from_tfds: bool, whether use tfds or read raw audio.
        Returns:
            tf.data.Dataset, data loader.
        """
        if from_tfds:
            dataset, info = tfds.load(
                'ljspeech', split='train',
                data_dir=data_dir, download=download, with_info=True)
            # filter only audio
            return dataset.map(LJSpeech._preproc_tfds), info
        # generate file lists
        files = tf.data.Dataset.from_tensor_slices(
            [os.path.join(data_dir, n) for n in os.listdir(data_dir)])
        # read audio
        return files.map(LJSpeech._load_audio), None

    @staticmethod
    def _load_audio(path):
        """Load audio with tf apis.
        Args:
            path: str, wavfile path to read.
        Returns:
            tf.Tensor, [T], mono audio in range (-1, 1).
        """
        raw = tf.io.read_file(path)
        audio, _ = tf.audio.decode_wav(raw, desired_channels=1)
        return tf.squeeze(audio, axis=-1)

    @staticmethod
    def _preproc_tfds(datum):
        """Preprocess datum from tfds.
        Args:
            datum: Dict[str, tf.Tensor],
                id: [], string, string id.
                speech: [T], int64, audio signal in range (-MAXVALUE - 1, MAXVALUE).
                text: [], string, text.
                text_normalized: [], string, normalized text.
        Returns:
            tf.Tensor, [T], mono audio in range (-1, 1).
        """
        return tf.cast(datum['speech'], tf.float32) / LJSpeech.MAXVAL

    def normalizer(self, frames=16000):
        """Create LJSpeech normalizer, make fixed size segment in range(-1, 1).
        Args:
            frames: int, segment size, frame unit.
            from_tfds: bool, whether use tfds tfrecord or raw audio.
        Returns:
            Callable, normalizer.
        """
        def normalize(speech):
            """Normalize datum.
            Args:
                speech: tf.Tensor, [T], mono audio in range (-1, 1).
            Returns:
                tf.Tensor, [frames], fixed size speech signal in range (-1, 1). 
            """
            nonlocal frames
            frames = frames // self.config.hop * self.config.hop
            start = tf.random.uniform(
                (), 0, tf.shape(speech)[0] - frames, dtype=tf.int32)
            return speech[start:start + frames]

        return normalize

    def mel_fn(self, signal):
        """Generate log mel-spectrogram from input audio segment.
        Args:
            signal: tf.Tensor, [B, T], audio segment.
        Returns:
            tuple,
                signal: tf.Tensor, [B, T], identity to inputs.
                logmel: tf.Tensor, [B, T // hop, mel], log mel-spectrogram.
        """
        padlen = self.config.win // 2
        # [B, T + win - 1]
        center_pad = tf.pad(signal, [[0, 0], [padlen, padlen - 1]], mode='reflect')
        # [B, T // hop, fft // 2 + 1]
        stft = tf.signal.stft(
            center_pad,
            frame_length=self.config.win,
            frame_step=self.config.hop,
            fft_length=self.config.fft,
            window_fn=self.config.window_fn())
        # [B, T // hop, mel]
        mel = tf.abs(stft) @ self.melfilter
        # [B, T // hop, mel]
        logmel = tf.math.log(tf.maximum(mel, self.config.eps))
        return signal, logmel

    def dataset(self):
        """Generate dataset.
        """
        if self.normalized is None:
            self.normalized = self.rawset \
                .map(self.normalizer(self.config.frames)) \
                .batch(self.config.batch) \
                .map(self.mel_fn)
        return self.normalized